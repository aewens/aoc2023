# Advent of Code 2023 - Abridged Edition

The rules of the game are a bit different here. This is done as an effort to keep with the spirit of the holiday while not doing something quite so frustrating and time consuming.
The following are the objectives we are going to try and reach, feel free to play along:

## Ewenix

Steps:

1. Create a **REPL** (Read-Eval-Print Loop). Accepts the commands `help`, `print`, and `quit`, otherwise loops waiting for a valid command. The `print` command will print whatever you send it back, the `quit` command will exit the loop, and the `help` command will display what commands there are and what they do.
2. Write a tool that will simulate running commands through the REPL and return what results it will get. Use this to verify the behavior of `help`, `print`, `quit`, and an invalid command. Lastly, add a benchmark to determine how quickly it can handle 1,000 commands for each command and return an output.
3. Add in a job scheduler using a **priority queue**. This will work by having any valid command queued to the job scheduler. The earlier a job is submitted, the sooner it gets run by the job scheduler. For now, the job will just consist of an ID, a time stamp for when it was submitted, and the action it will perform once it is its turn. The job ID will begin at 2 and increment by 1 for each new job added (since we will assume the REPL is job ID 1), To help this make sense, a new command `echo` will be added that takes two arguments where the first is a number. The number is how long the job will be suspended, and the second argument is what will be printed to the screen after the job is no longer suspended. To test this, submit 1,000 `echo` commands with randomly generated numbers and the second argument matching and use the simulator above to ensure they are returned in order of lowest to highest. Be sure to also note how long it takes to accomplish this.
4. Add in a memory management controller (MMC) using a **Binary Min-Heap** and the **Binary** **Buddy Allocation** algorithm. This fantasy machine will have 32,768 memory locations of 1 byte or 8 bits (i.e. 32kb of memory) called the Stack. By default the Stack will be initialized as 0 in all locations. When keeping track of allocated blocks, the block size will be 32 bytes; so with 32kb that’s 1,024 blocks, and since each byte can track 8 blocks using a bit mask we only need 128 bytes to track this. So the **first 128 bytes** of memory will be reserved for tracking the allocated blocks. The MMC will function by adding in the commands `alloc`, `free`, `write`, and `read`. The `alloc` command takes an argument of how many bytes allocate from the Stack and return the starting memory address of the block allocated (should return an **out-of-memory** / **OOM** **error** if all the memory is already allocated). The `free` command will take the same memory address given by `alloc` to free that allocated block back to the Stack. The `write` command will take at minimum two arguments, the first is the memory address to start at and every argument afterwards will be the number written to the memory location offset by the argument (e.g. the first argument will be written to the memory address given, the second will be at the memory address+1, the third will be at the memory address+2, and so on); and should return an **out-of-bounds** / **OOB error** if a value is given that is less than 0 or greater than 255 (since each location is only a single byte of data). The `read` command will take two arguments, the first is a starting memory address and the second is how many bytes to read from the Stack. To verify that this works, try allocating all 32,768 locations and see if allocating another byte works or returns an error; dump the first 4 bytes to verify they are still zeros; free it all and try allocating 4 bytes; write 1 2 3 4 to those allocated bytes followed by freeing them; and finally dump the four bytes at the memory address to verify that the data is still written. Be sure to also note how long it takes to accomplish this.
5. Let’s implement a way to encode/decode data. To start, let’s use ASCII + [Bencode](https://en.wikipedia.org/wiki/Bencode). We will add a special `bwrite` and `bread` command to support this, which will work exactly the same as `write` and `read`, except taking in **bencode** as input and returning **bencode** as output. Use this to encode the data structure `{"key": "value", "numbers": [1,2,3]}` onto the Stack and then return it again using `bwrite` and `bread`. As an implementation detail, for now just ignore the control characters from ASCII 1-31.
6. To add some safety to the MMC, we will use a **lookup table** to ensure only the process that allocated the memory is allowed to free it, write to it, and dump it. The new command `run` will be added to execute commands sequentially to help leverage this new feature, such that once a command completes the job ID will be passed from the previous command to the next command to access the shared memory (as an implementation detail, this means the job scheduler will see all of the jobs queued by `run` using the same job ID). This will require the `alloc`, `free`, `write`, and `read` commands to pass along the job ID that launched them when attempting to access the Stack over the MMC (to keep the REPL useful, anything not launched via `run` will use the job ID 1 for its memory blocks). The `run` command will take a series of arguments delimited by a semicolon to separate the chained commands it will queue to the job scheduler. To verify that this works, setup the simulator tool to use the `run` command to run `alloc` and pass the memory address returned to another instance of `run` issuring `free` on the same memory address, this should return an **unauthorized memory access** / **UMA error**. Then issue another `run` instance that performs the same test from the previous day. Be sure to also note how long it takes to accomplish this.
7. Next we will implement the persistent storage, which will be similar to the memory but the fantasy machine will use here a drive with 1,024 sectors that are 256 bytes or 2,048 bits each (i.e. 256kb of storage). At an implementation level, this is just 1,024 separate arrays of size 2,048; each element initialized at 0. The first 128 sectors (or 32kb) are reserved for the file system. The file system will have entries for cataloging files and directories, each entry will be 32 bytes. They first byte is an unsigned char that will identify what type of entry it is (0 for file, 1 for directory). The next three bytes will be three more unsigned chars to designate what sector the file starts in, what the offset in the sector is where the file starts, and the size of the file. The next four bytes are an unsigned int for is the attributes for the file set using bit masks. Followed is eight bytes  will hold a timestamp when the file was last modified. The last 16 bytes of the entry will be ASCII encoded text for the name of the entry. To keep track of allocated space, the first reserved sectors will be used for marking which blocks are currently allocated using bitmasked bytes for the allocation map. The remaining 127 reserved sectors are for the file system metadata. Since an entry is 32 bytes and a sector contains 256 bytes, there can be 8 entries per each sector. Given 127 sectors for the file system, that allows for a max of 1,016 entries. This is why only the first sector is needed for the allocation map because 1,016 bits can fit into 127 bytes, less than the 256 bytes of a single sector. The other 129 bytes in the first sector will remain intentionally unused, and the metadata will begin on the second sector of its first byte. The Binary Buddy Allocation algorithm will be used again for tracking block usage. The root directory will implicitly always exist, and everything written to the top-level files and directories will implicitly belong to it. To list the directories and files created use ls without any arguments to list them in the order they appear in the file system. The commands dir and file will also be added to create directories and files, respectively. To test this, create a file and directory and run ls to list them both and their properties.
8. Implement file navigation by adding the `cd`, `pwd`, and `tree` commands. The `cd` command will change directory to an available directory in the current directory, which should prompt the file system to change its pointer to the new directory and load in its contents from the storage (using `..` will move the pointer up to the parent directory); as an implementation detail, load the contents of the working directory as an **AVL Tree**. The `pwd` command will print the absolute path of then current working directory. The `tree` command should list every file and sub-directory recursively from the current directory. To test this new file system, create two directories called “0” and “1”, in each directory do the same thing 8 levels deep, and at the 8th level create two files named “0” and “1”. By the end, in the root directory the `tree` command should have 512 (2^9) files going from `0/0/0/0/0/0/0/0/0` to `1/1/1/1/1/1/1/1/1`. Be sure to also note how long it takes to print the `tree` command.
9. To clean up files and directories add `rm` and `rmtree` to remove files and directories (recursively). You may note this will leave holes in the allocation map over time as blocks are added and removed. To make this more maintainable, also add a `defrag` command to squash all of the blocks back to being dense instead of sparse. To test this delete the `0` directory and run `defrag`, note how long this takes to compete for both tasks.
10. To make the file system useful add `fwrite`, `fread`, `bfwrite`, and `bfread` as analogs to `write`, `read`, `bwrite`, and `bread` for the memory, but for files. This will work almost exactly the same way, but instead of a memory address the file name / file path should be given. If the file does not exist, and the parent directories do, these commands should also create the file for you before writing to them. File path resolution will need to be added to determine which file entry belongs to a file path (assume either absolute paths or paths relative to the current directory or sub-directory, not upwards). As an implementation detail, the writes should be streamed into memory and flushed to disk in chunks of 32 bytes, and reads should be loaded from disk into memory before printing. To test the new commands, recreate the `0` directory deleted above and its 256 entries, but for reach file write the full path name as the contents using `bfwrite`. Verify afterwards that it works using the `bfread` command and more how long both actions take.
    1. As a performance optimization, a **Bloom Filter** can be added to quickly check if a file path exists or not (this will be left optional depending on time).
11. Now to implement a maze generator. Use a **backtracking recursive algorithm** to generate solvable mazes where the path begins at the top left corner and ends at the bottom right corner. More specifically, the maze should be 17x17 including the walls outlining the maze, where in (x, y) format assuming (0, 0) is the top-left corner the entrance is at (1, 0) and ends at (16, 17). The maze should be generated using the `maze` command that outputs the path to the maze generated into the current directory as a single file using a random name. Another command `pmaze` should be added where the file path of a maze is given and it prints it to the console where the walls are `#` and the path is a space. The file format will be left as an exercise to the reader. The `pmaze` command should record how large the resulting file format is, how long it takes to generate the maze, amd how long it takes to draw it; and after drawing the maze print those three numbers. Verify that running the command twice generates two different and solvable mazes.
    1. Since the file format is left on you to decide for the maze, I should note now that for tomorrow the maze will be translated from XY coordinates to a graph. Read ahead if you want to make this format more compatible ahead of time.
12. The last is implementing a maze solver. This will be done in the form of adding the command `solve` that will take a path to a maze file as input and as an output re-draw the maze solved. This will be done by using the `*` character to draw the path to take for solving the maze and otherwise use the same drawing characters as `pmaze` from yesterday. The solver will work by translating the maze into a **weighted graph** of the maze intersections such that the weight of the edges is how many spaces are between it and the node it is connected to. Use the **DFS** **algorithm** to generate the graph for this step. Next, use **Dijkstra’s algorithm** to find the shortest path to the end of the maze. Once the shortest path is found, draw the solved maze to the console (this may require translating the graph back to the XY coordinates). For each of the tree steps (translate, solving, and drawing) add a timer to determine how long each took, and at the end of drawing the solved maze display those three numbers. Verify that when `solve` is run it returns the same solution to the maze each time.

Ways to play: one a day for “Twelve Days of Codemas” or two days for each step for “Advent of Codemas”
